{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47da52c-a63d-41ce-8a12-d11fee42cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587956bd-27c2-4df6-814a-17975b706ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"/root/segment-anything-2/checkpoints/sam2_hiera_tiny.pt\"\n",
    "model_cfg = \"sam2_hiera_t.yaml\"\n",
    "predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0d7461-2451-4b93-9d7e-64d1d0eb2a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SAM2Base._prepare_backbone_features() missing 1 required positional argument: 'backbone_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_backbone_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SAM2Base._prepare_backbone_features() missing 1 required positional argument: 'backbone_out'"
     ]
    }
   ],
   "source": [
    "predictor.model._prepare_backbone_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0eb3cdb-7df7-4478-b2aa-da6233144504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MedSAM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_encoder,\n",
    "        mask_decoder,\n",
    "        prompt_encoder,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.mask_decoder = mask_decoder\n",
    "        self.prompt_encoder = prompt_encoder\n",
    "        # freeze prompt encoder\n",
    "        for param in self.prompt_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, image, box):\n",
    "        image_embedding = self.image_encoder(image)  # (B, 256, 64, 64)\n",
    "        # do not compute gradients for prompt encoder\n",
    "        with torch.no_grad():\n",
    "            box_torch = torch.as_tensor(box, dtype=torch.float32, device=image.device)\n",
    "            if len(box_torch.shape) == 2:\n",
    "                box_torch = box_torch[:, None, :]  # (B, 1, 4)\n",
    "\n",
    "            sparse_embeddings, dense_embeddings = self.prompt_encoder(\n",
    "                points=None,\n",
    "                boxes=box_torch,\n",
    "                masks=None,\n",
    "            )\n",
    "        low_res_masks, _ = self.mask_decoder(\n",
    "            image_embeddings=image_embedding,  # (B, 256, 64, 64)\n",
    "            image_pe=self.prompt_encoder.get_dense_pe(),  # (1, 256, 64, 64)\n",
    "            sparse_prompt_embeddings=sparse_embeddings,  # (B, 2, 256)\n",
    "            dense_prompt_embeddings=dense_embeddings,  # (B, 256, 64, 64)\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        ori_res_masks = F.interpolate(\n",
    "            low_res_masks,\n",
    "            size=(image.shape[2], image.shape[3]),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        return ori_res_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26484224-66b1-4815-9f19-46d4c1311546",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sam_model = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint)).model\n",
    "\n",
    "    # sam_model = sam_model_registry[args.model_type](checkpoint=args.checkpoint)\n",
    "    medsam_model = MedSAM(\n",
    "        image_encoder=sam_model.image_encoder,\n",
    "        mask_decoder=sam_model.sam_mask_decoder,\n",
    "        prompt_encoder=sam_model.sam_prompt_encoder,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2eb2a1a-cafc-4c37-8150-96a7cec94821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedSAM(\n",
       "  (image_encoder): ImageEncoder(\n",
       "    (trunk): Hiera(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "        (1): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "          (proj): Linear(in_features=96, out_features=192, bias=True)\n",
       "        )\n",
       "        (2): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "        (3): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "          (proj): Linear(in_features=192, out_features=384, bias=True)\n",
       "        )\n",
       "        (4-9): 6 x MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "        (10): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "          (proj): Linear(in_features=384, out_features=768, bias=True)\n",
       "        )\n",
       "        (11): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): FpnNeck(\n",
       "      (position_encoding): PositionEmbeddingSine()\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (conv): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            )\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (obj_score_token): Embedding(1, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "        (act): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (pred_obj_score_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "      (act): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medsam_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b839bd-12d3-4a9a-80a5-959172096518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
